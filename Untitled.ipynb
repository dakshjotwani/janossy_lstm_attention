{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'transformer' from 'M:\\\\MyFiles\\\\Classes\\\\2020 Spring\\\\cs690\\\\project\\\\janossy_lstm_attention\\\\transformer.py'>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import train\n",
    "import transformer\n",
    "import lstm_tran\n",
    "importlib.reload(train)\n",
    "importlib.reload(lstm_tran)\n",
    "importlib.reload(transformer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=16, copy_opt=False, cuda=True, d_inner_hid=2048, d_k=64, d_model=512, d_v=64, d_word_vec=512, data_pkl='m30k_deen_shr.pkl', dropout=0.1, embs_share_weight=True, epoch=2, label_smoothing=True, load_model=None, log=None, lstm=False, max_token_seq_len=100, n_head=8, n_layers=6, n_warmup_steps=128000, no_cuda=False, proj_share_weight=True, save_mode='best', save_model='trained', src_pad_idx=1, src_vocab_size=9521, train_path=None, trg_pad_idx=1, trg_vocab_size=9521, val_path=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  - (Training)   :   0%|                                                                      | 0/1813 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch 0 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-3cc3a1c99699>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_tran\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-121-3cc3a1c99699>\u001b[0m in \u001b[0;36mstart\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#                 '-proj_share_weight', '-label_smoothing', '-save_model', 'trained', '-load_model', 'trained',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#                 '-b', '4', '-warmup', '128000', '-epoch', '150']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_tran\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\MyFiles\\Classes\\2020 Spring\\cs690\\project\\janossy_lstm_attention\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\MyFiles\\Classes\\2020 Spring\\cs690\\project\\janossy_lstm_attention\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, training_data, validation_data, optimizer, device, opt, continue_from_epoch)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         train_loss, train_accu = train_epoch(\n\u001b[1;32m--> 170\u001b[1;33m             model, training_data, optimizer, opt, device, smoothing=opt.label_smoothing)\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[0mprint_performances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\MyFiles\\Classes\\2020 Spring\\cs690\\project\\janossy_lstm_attention\\train.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, training_data, optimizer, opt, device, smoothing)\u001b[0m\n\u001b[0;32m     91\u001b[0m         loss, n_correct, n_word = cal_performance(\n\u001b[0;32m     92\u001b[0m             pred, gold, opt.trg_pad_idx, smoothing=smoothing) \n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_and_update_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\Users\\Master\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\Users\\Master\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def start():\n",
    "    sys.argv = ['train.py', '-data_pkl', 'm30k_deen_shr.pkl', '-embs_share_weight', \n",
    "                '-proj_share_weight', '-label_smoothing', '-save_model', 'trained', \n",
    "                '-b', '16', '-warmup', '128000', '-epoch', '2']\n",
    "#     sys.argv = ['train.py', '-data_pkl', 'm30k_deen_shr.pkl', '-embs_share_weight', \n",
    "#                 '-proj_share_weight', '-label_smoothing', '-save_model', 'trained', '-load_model', 'trained', \n",
    "#                 '-b', '4', '-warmup', '128000', '-epoch', '150']\n",
    "    train.main()\n",
    "importlib.reload(lstm_tran)\n",
    "\n",
    "start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run train.py -data_pkl m30k_deen_shr.pkl -embs_share_weight -proj_share_weight -label_smoothing -save_model trained -b 8 -warmup 128000 -epoch 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros((3, 10)).long()\n",
    "b = torch.tensor([1, 1, 2]).long()\n",
    "a.scatter(1, b.view(-1, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4200, 4201, 4202, 4203, 4204],\n",
       "        [4205, 4206, 4207, 4208, 4209],\n",
       "        [4210, 4211, 4212, 4213, 4214],\n",
       "        [4215, 4216, 4217, 4218, 4219],\n",
       "        [4220, 4221, 4222, 4223, 4224]], dtype=torch.int32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[np.arange(0, 25).reshape(5, 5)+((i)*100)+((j)*1000) for i in range(5)] for j in range(16)])\n",
    "a = torch.tensor(a)\n",
    "a[4, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.triu(np.ones((5, 5)))[None, None, :].repeat(16, axis=0)\n",
    "mask = torch.tensor(mask)\n",
    "mask[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5, 5, 5]) torch.Size([16, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# a.masked_fill(mask == 0, -1e9)\n",
    "print(a.shape, mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(num_examples, seq_len, n_dim, std):\n",
    "    train_x = torch.normal(torch.zeros(seq_len*n_dim*num_examples), torch.ones(seq_len*n_dim*num_examples)*std).view(num_examples, seq_len, n_dim)\n",
    "    means = torch.mean(train_x, dim=2)\n",
    "    maxes = torch.max(train_x, dim=2).values\n",
    "    sum_of_means = means.sum(dim=1)\n",
    "    train_y = maxes + sum_of_means[:, None] - means\n",
    "#     train_y = maxes\n",
    "    return train_x, train_y.unsqueeze(-1)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(MyDataset, self).__init__()\n",
    "        assert x.shape[0] == y.shape[0] # assuming shape[0] = dataset size\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "seq_len = 10\n",
    "n_dim = 5\n",
    "num_examples = 1024*10\n",
    "std = 1\n",
    "train_x, train_y = create_data(num_examples, seq_len, n_dim, std)\n",
    "traindata = MyDataset(train_x, train_y)\n",
    "traindata_tran = MyDataset(train_x, torch.cat((torch.zeros(train_y.shape[:-1]+(4,)), train_y), dim=-1))\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=1024, shuffle=True)\n",
    "trainloader_tran = torch.utils.data.DataLoader(traindata_tran, batch_size=1024, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq = np.array([4, 10, 17, 24, 101, 105, 102, 1000])\n",
    "# indices = np.arange(seq.shape[0])\n",
    "# reverse_indices = np.arange(seq.shape[0])\n",
    "# indices_arange = np.arange(seq.shape[0])\n",
    "# rep = 2\n",
    "# for r in range(rep):\n",
    "#     for i in range(len(indices)):\n",
    "#         np.random.shuffle(indices)\n",
    "#         ind = np.where(indices==i)[0][0]\n",
    "#         indices[[ind, -1]] = indices[[-1, ind]]\n",
    "#         reverse_indices[indices] = indices_arange\n",
    "#         permuted_input = seq[indices]\n",
    "#         print(permuted_input)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class janossyLastOnlyLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim, janossy_count, dropout=0):\n",
    "        super(janossyLastOnlyLSTM, self).__init__()\n",
    "        self.janossy_count = janossy_count\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_size = input_dim, hidden_size = hidden_dim, dropout = dropout)\n",
    "        self.w1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.w2 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, seq, prin=False):\n",
    "        # lstm needs [seq_len, batch, input_size]\n",
    "        seq = seq.transpose(0, 1)\n",
    "        seq_len, batch_len, input_dim = seq.size()\n",
    "        \n",
    "        indices = np.arange(seq_len)\n",
    "        reverse_indices = np.arange(seq_len)\n",
    "        indices_arange = np.arange(seq_len)\n",
    "        \n",
    "        result = torch.zeros([seq_len, batch_len, self.hidden_dim], device=seq.device)\n",
    "        for _ in range(self.janossy_count):\n",
    "            for i in range(len(indices)):\n",
    "                np.random.shuffle(indices)\n",
    "                ind = np.where(indices==i)[0][0]\n",
    "                indices[[ind, -1]] = indices[[-1, ind]]\n",
    "                reverse_indices[indices] = indices_arange\n",
    "                \n",
    "                permuted_input = seq[indices]\n",
    "                \n",
    "#                 print(permuted_input)\n",
    "                _, (last_h, _) = self.lstm(permuted_input)\n",
    "                result[i] += last_h.squeeze(0)\n",
    "#                 print(permuted_input.shape)\n",
    "\n",
    "        result = result / self.janossy_count\n",
    "        # get result of shape [batch, seq_len, hidden_size]\n",
    "        result = result.transpose(0, 1)\n",
    "        result = self.w2(F.relu(self.w1(result)))\n",
    "#         if prin:\n",
    "#             print('res:', result[0,:2])\n",
    "#         result = torch.log((result+1)/(1-result))\n",
    "#         if prin:\n",
    "#             print('resA:', result[0,:2])\n",
    "        return result\n",
    "# janossyLastOnlyLSTM(4, 4, 1)(torch.arange(64, dtype=torch.float).reshape(4, 4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "loss: 0.29534196853637695\n",
      "y: tensor([[1.8413],\n",
      "        [1.7670]])\n",
      "out: tensor([[1.5810],\n",
      "        [1.7464]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(transformer)\n",
    "class janossyLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, janossy_count, dropout=0):\n",
    "        super(janossyLSTM, self).__init__()\n",
    "        self.janossy_count = janossy_count\n",
    "        self.lstm = nn.LSTM(input_size = input_dim, hidden_size = hidden_dim, dropout = dropout)\n",
    "\n",
    "    def forward(self, seq, prin=False):\n",
    "        \n",
    "        # lstm needs [seq_len, batch, input_size]\n",
    "        seq = seq.transpose(0, 1)\n",
    "        \n",
    "        indices = np.arange(seq.size(0))\n",
    "        reverse_indices = np.arange(seq.size(0))\n",
    "        indices_arange = np.arange(seq.size(0))\n",
    "        \n",
    "        result = torch.zeros_like(seq[:,:,0:1])\n",
    "\n",
    "        for _ in range(self.janossy_count):\n",
    "            np.random.shuffle(indices)\n",
    "            reverse_indices[indices] = indices_arange\n",
    "            \n",
    "            permuted_input = seq[indices]\n",
    "            permuted_out, _ = self.lstm(permuted_input)\n",
    "            out = permuted_out[reverse_indices]\n",
    "            result += out[:,:,0:1]\n",
    "\n",
    "        result = result / self.janossy_count\n",
    "        # get result of shape [batch, seq_len, hidden_size]\n",
    "        result = result.transpose(0, 1)\n",
    "#         if prin:\n",
    "#             print('res:', result[0,:2])\n",
    "#         result = torch.log((result+1)/(1-result))\n",
    "#         if prin:\n",
    "#             print('resA:', result[0,:2])\n",
    "        return result\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "# device = 'cpu'\n",
    "\n",
    "# model = janossyLSTM(n_dim, 1, janossy_count=2)\n",
    "# model = janossyLastOnlyLSTM(input_dim=n_dim, hidden_dim=10, out_dim=1, janossy_count=1).to(device)\n",
    "# model = transformer.Transformer_embed_ready_test(d_model=5, d_inner=100, n_layers=1, n_head=1, d_k=4, d_v=4, dropout=0)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-04)\n",
    "\n",
    "for epoch in range(1):\n",
    "    print('epoch', epoch)\n",
    "    for i, (mini_x, mini_y) in enumerate(trainloader):\n",
    "        model.zero_grad()\n",
    "        out = model(mini_x.to(device), prin=epoch%5==0 and i==0)\n",
    "        \n",
    "        loss = loss_function(out, mini_y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch%20==0 and i==0:\n",
    "            print('loss:', loss.item())\n",
    "            print('y:', mini_y[0,:2])\n",
    "            print('out:', out[0,:2])\n",
    "            print('-----------')\n",
    "    #         print(out[0][0], mini_y[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.9269,  2.4873,  1.9007, -1.1055],\n",
      "         [ 1.6784, -0.2345,  0.9569, -0.6047],\n",
      "         [ 1.3559,  0.3134,  0.5066,  1.2415]],\n",
      "\n",
      "        [[-0.1109,  1.0915, -1.3169,  0.7832],\n",
      "         [ 0.6903,  0.6043,  1.8034,  0.3784],\n",
      "         [ 0.4080,  0.9369,  0.1714,  1.3309]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.9871, 1.1214])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a, b, c = 2, 3, 4\n",
    "t = torch.normal(torch.ones(a, b, c))\n",
    "print(t)\n",
    "\n",
    "mean = t.mean(dim=1)\n",
    "# print(mean)\n",
    "\n",
    "# threshold = 1\n",
    "# mean[mean<threshold] = 0\n",
    "# print(mean)\n",
    "\n",
    "mean[mean>=threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "loss: 2.7860851287841797\n",
      "valid loss: 2.767327308654785\n",
      " y : [3.5395567 2.8789594 2.7861435 1.9524927 1.9652911]\n",
      "out: [0.4497175  0.43724886 0.4450761  0.4409662  0.4458222 ]\n",
      "dlt: [-3.0898392 -2.4417105 -2.3410673 -1.5115266 -1.5194689]\n",
      " % : [-87.294525 -84.812256 -84.02537  -77.41522  -77.31521 ]\n",
      "-----------\n",
      "epoch:  21 22 23 24 25 26 27 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mM:\\MyFiles\\Classes\\2020 Spring\\cs690\\project\\janossy_lstm_attention\\lstm_test.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmini_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\Users\\Master\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\MyFiles\\Classes\\2020 Spring\\cs690\\project\\janossy_lstm_attention\\lstm_test.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, seq, prin)\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mreverse_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_arange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m                 \u001b[0mpermuted_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#                 print(permuted_input)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run lstm_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num = 10\n",
    "result = [np.empty((5, 5)) for _ in range(num)]\n",
    "result\n",
    "np.shape(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10]) torch.Size([10000, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = train_x.max(dim=2).values\n",
    "# g = g[:, :, None]\n",
    "print(g.shape, mean(train_x, dim=2).sum(dim=1, keepdims=True).shape)\n",
    "# g = g + mean(train_x, dim=2).sum(dim=1, keepdims=True)\n",
    "# g = torch.tanh(g[:,:,None])\n",
    "g = g[:,:,None]\n",
    "loss_function(g, train_y)\n",
    "# train_y.shape\n",
    "# train_x.max(dim=-1, keepdims=True).values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 2, 6, 1, 4, 5, 9, 8, 0])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.arange(10)\n",
    "t[indices] = np.arange(10)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulge = pd.DataFrame(zip([0, 0.5, 1, 1.1, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3], [1.5, 0, 0, 0, 1, 9.2, 11, 9.5, 10, 10]), columns=['z', 'age'])\n",
    "# bulge\n",
    "# height = [i for i, x in enumerate(bulge['z']) if 1<x<1.25]\n",
    "# age1 = [i for i, x in enumerate(bulge['age']) if x<0.1]\n",
    "# age2 = [i for i, x in enumerate(bulge['age']) if 9<x<10]\n",
    "\n",
    "# ageheight1=bulge[height and age1]\n",
    "# ageheight2=bulge[height and age2]\n",
    "ageheight1 = bulge[ (bulge['age']<0.1) & (bulge['z']<1.25) & (bulge['z']>1)]\n",
    "ageheight2 = bulge[ (bulge['age']<10) & (bulge['age']>9) & (bulge['z']<1.25) & (bulge['z']>1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fake data\n",
    "np.random.seed(42)\n",
    "# the variable length of inner lists: [7270,  860, 5390, ..., 1389, 4276, 1249]\n",
    "inner_sizes = np.random.randint(low=1, high=1000, size=10000)\n",
    "ppValues = [np.random.randint(1000, size=i) for i in inner_sizes]\n",
    "# ppValues contains 10000 lists, each having 1 to 1000 elements, each element is a number between 1 to 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.linspace(0, 1, 100)\n",
    "m = nn.LSTM(2, 3)\n",
    "# for p in m.parameters():\n",
    "#     print(p)\n",
    "#     print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame([0.1, 0.2, 0.3, 0.4, 0.5], index=[1, 2, 3, 4, 5], columns=['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 5, 5, 101]"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_factors(n):\n",
    "    res = []\n",
    "    while n != 1:\n",
    "        for i in range(2, int(np.sqrt(n))+1):\n",
    "            if n%i == 0:\n",
    "                res.append(i)\n",
    "                n //= i\n",
    "                break\n",
    "        else:\n",
    "            res.append(n)\n",
    "            break\n",
    "    return res\n",
    "        \n",
    "get_factors(20200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "param_grid = {'n_epochs': [1]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15096.0\n",
      "21565.714285714286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28035.428571428572"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coal   75292 74164 73904 73732 71920 65000 60384 54024 \n",
    "# ingots 10731 11216 11323 11400 12260 15506 17628 20553\n",
    "n = 60384/4\n",
    "not_consume_chance = 0.3\n",
    "breaks=scipy.stats.nbinom.mean(n, p=1-not_consume_chance)+n\n",
    "print(n)\n",
    "print(breaks)\n",
    "scipy.stats.binom.mean(breaks, p=not_consume_chance)+breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4160.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ingots   20553 \n",
    "# plates   0     \n",
    "ingots = 3200\n",
    "scipy.stats.binom.mean(ingots, p=not_consume_chance)+ingots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
