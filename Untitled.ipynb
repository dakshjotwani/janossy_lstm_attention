{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import train\n",
    "import transformer\n",
    "importlib.reload(train)\n",
    "importlib.reload(transformer)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def start():\n",
    "    sys.argv = ['train.py', '-data_pkl', 'm30k_deen_shr.pkl', '-embs_share_weight', \n",
    "                '-proj_share_weight', '-label_smoothing', '-save_model', 'trained', \n",
    "                '-b', '16', '-warmup', '128000', '-epoch', '2']\n",
    "    sys.argv = ['train.py', '-data_pkl', 'm30k_deen_shr.pkl', '-embs_share_weight', \n",
    "                '-proj_share_weight', '-label_smoothing', '-save_model', 'trained', '-load_model', 'trained', \n",
    "                '-b', '4', '-warmup', '128000', '-epoch', '150']\n",
    "    train.main()\n",
    "# start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run train.py -data_pkl m30k_deen_shr.pkl -log m30k_deen_shr -embs_share_weight -proj_share_weight -label_smoothing -save_model trained -load_model trained -b 8 -warmup 128000 -epoch 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros((3, 10)).long()\n",
    "b = torch.tensor([1, 1, 2]).long()\n",
    "a.scatter(1, b.view(-1, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4200, 4201, 4202, 4203, 4204],\n",
       "        [4205, 4206, 4207, 4208, 4209],\n",
       "        [4210, 4211, 4212, 4213, 4214],\n",
       "        [4215, 4216, 4217, 4218, 4219],\n",
       "        [4220, 4221, 4222, 4223, 4224]], dtype=torch.int32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[np.arange(0, 25).reshape(5, 5)+((i)*100)+((j)*1000) for i in range(5)] for j in range(16)])\n",
    "a = torch.tensor(a)\n",
    "a[4, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.triu(np.ones((5, 5)))[None, None, :].repeat(16, axis=0)\n",
    "mask = torch.tensor(mask)\n",
    "mask[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5, 5, 5]) torch.Size([16, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# a.masked_fill(mask == 0, -1e9)\n",
    "print(a.shape, mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(num_examples, seq_len, n_dim, std):\n",
    "    train_x = torch.normal(torch.zeros(seq_len*n_dim*num_examples), torch.ones(seq_len*n_dim*num_examples)*std).view(num_examples, seq_len, n_dim)\n",
    "    means = torch.mean(train_x, dim=2)\n",
    "    maxes = torch.max(train_x, dim=2).values\n",
    "    sum_of_means = means.sum(dim=1)\n",
    "    train_y = maxes + sum_of_means[:, None] - means\n",
    "#     train_y = maxes\n",
    "    return train_x, train_y.unsqueeze(-1)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(MyDataset, self).__init__()\n",
    "        assert x.shape[0] == y.shape[0] # assuming shape[0] = dataset size\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "seq_len = 10\n",
    "n_dim = 5\n",
    "num_examples = 1024*10\n",
    "std = 1\n",
    "train_x, train_y = create_data(num_examples, seq_len, n_dim, std)\n",
    "traindata = MyDataset(train_x, train_y)\n",
    "traindata_tran = MyDataset(train_x, torch.cat((torch.zeros(train_y.shape[:-1]+(4,)), train_y), dim=-1))\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=1024, shuffle=True)\n",
    "trainloader_tran = torch.utils.data.DataLoader(traindata_tran, batch_size=1024, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq = np.array([4, 10, 17, 24, 101, 105, 102, 1000])\n",
    "# indices = np.arange(seq.shape[0])\n",
    "# reverse_indices = np.arange(seq.shape[0])\n",
    "# indices_arange = np.arange(seq.shape[0])\n",
    "# rep = 2\n",
    "# for r in range(rep):\n",
    "#     for i in range(len(indices)):\n",
    "#         np.random.shuffle(indices)\n",
    "#         ind = np.where(indices==i)[0][0]\n",
    "#         indices[[ind, -1]] = indices[[-1, ind]]\n",
    "#         reverse_indices[indices] = indices_arange\n",
    "#         permuted_input = seq[indices]\n",
    "#         print(permuted_input)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class janossyLastOnlyLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim, janossy_count, dropout=0):\n",
    "        super(janossyLastOnlyLSTM, self).__init__()\n",
    "        self.janossy_count = janossy_count\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_size = input_dim, hidden_size = hidden_dim, dropout = dropout)\n",
    "        self.w1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.w2 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, seq, prin=False):\n",
    "        # lstm needs [seq_len, batch, input_size]\n",
    "        seq = seq.transpose(0, 1)\n",
    "        seq_len, batch_len, input_dim = seq.size()\n",
    "        \n",
    "        indices = np.arange(seq_len)\n",
    "        reverse_indices = np.arange(seq_len)\n",
    "        indices_arange = np.arange(seq_len)\n",
    "        \n",
    "        result = torch.zeros([seq_len, batch_len, self.hidden_dim], device=seq.device)\n",
    "        for _ in range(self.janossy_count):\n",
    "            for i in range(len(indices)):\n",
    "                np.random.shuffle(indices)\n",
    "                ind = np.where(indices==i)[0][0]\n",
    "                indices[[ind, -1]] = indices[[-1, ind]]\n",
    "                reverse_indices[indices] = indices_arange\n",
    "                \n",
    "                permuted_input = seq[indices]\n",
    "                \n",
    "#                 print(permuted_input)\n",
    "                _, (last_h, _) = self.lstm(permuted_input)\n",
    "                result[i] += last_h.squeeze(0)\n",
    "#                 print(permuted_input.shape)\n",
    "\n",
    "        result = result / self.janossy_count\n",
    "        # get result of shape [batch, seq_len, hidden_size]\n",
    "        result = result.transpose(0, 1)\n",
    "        result = self.w2(F.relu(self.w1(result)))\n",
    "#         if prin:\n",
    "#             print('res:', result[0,:2])\n",
    "#         result = torch.log((result+1)/(1-result))\n",
    "#         if prin:\n",
    "#             print('resA:', result[0,:2])\n",
    "        return result\n",
    "# janossyLastOnlyLSTM(4, 4, 1)(torch.arange(64, dtype=torch.float).reshape(4, 4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "loss: 0.29534196853637695\n",
      "y: tensor([[1.8413],\n",
      "        [1.7670]])\n",
      "out: tensor([[1.5810],\n",
      "        [1.7464]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(transformer)\n",
    "class janossyLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, janossy_count, dropout=0):\n",
    "        super(janossyLSTM, self).__init__()\n",
    "        self.janossy_count = janossy_count\n",
    "        self.lstm = nn.LSTM(input_size = input_dim, hidden_size = hidden_dim, dropout = dropout)\n",
    "\n",
    "    def forward(self, seq, prin=False):\n",
    "        \n",
    "        # lstm needs [seq_len, batch, input_size]\n",
    "        seq = seq.transpose(0, 1)\n",
    "        \n",
    "        indices = np.arange(seq.size(0))\n",
    "        reverse_indices = np.arange(seq.size(0))\n",
    "        indices_arange = np.arange(seq.size(0))\n",
    "        \n",
    "        result = torch.zeros_like(seq[:,:,0:1])\n",
    "\n",
    "        for _ in range(self.janossy_count):\n",
    "            np.random.shuffle(indices)\n",
    "            reverse_indices[indices] = indices_arange\n",
    "            \n",
    "            permuted_input = seq[indices]\n",
    "            permuted_out, _ = self.lstm(permuted_input)\n",
    "            out = permuted_out[reverse_indices]\n",
    "            result += out[:,:,0:1]\n",
    "\n",
    "        result = result / self.janossy_count\n",
    "        # get result of shape [batch, seq_len, hidden_size]\n",
    "        result = result.transpose(0, 1)\n",
    "#         if prin:\n",
    "#             print('res:', result[0,:2])\n",
    "#         result = torch.log((result+1)/(1-result))\n",
    "#         if prin:\n",
    "#             print('resA:', result[0,:2])\n",
    "        return result\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "# device = 'cpu'\n",
    "\n",
    "# model = janossyLSTM(n_dim, 1, janossy_count=2)\n",
    "# model = janossyLastOnlyLSTM(input_dim=n_dim, hidden_dim=10, out_dim=1, janossy_count=1).to(device)\n",
    "# model = transformer.Transformer_embed_ready_test(d_model=5, d_inner=100, n_layers=1, n_head=1, d_k=4, d_v=4, dropout=0)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-04)\n",
    "\n",
    "for epoch in range(1):\n",
    "    print('epoch', epoch)\n",
    "    for i, (mini_x, mini_y) in enumerate(trainloader):\n",
    "        model.zero_grad()\n",
    "        out = model(mini_x.to(device), prin=epoch%5==0 and i==0)\n",
    "        \n",
    "        loss = loss_function(out, mini_y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch%20==0 and i==0:\n",
    "            print('loss:', loss.item())\n",
    "            print('y:', mini_y[0,:2])\n",
    "            print('out:', out[0,:2])\n",
    "            print('-----------')\n",
    "    #         print(out[0][0], mini_y[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "loss: 2.965898275375366\n",
      " y : [1.3367705  0.86900055 1.0219711  1.5175655  1.2426786 ]\n",
      "out: [0.395586   0.37367654 0.34317574 0.3848396  0.3680715 ]\n",
      "dlt: [-0.9411845  -0.49532402 -0.67879534 -1.132726   -0.87460715]\n",
      " % : [-70.40733 -56.99928 -66.42021 -74.64099 -70.3808 ]\n",
      "-----------\n",
      "epoch:  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mM:\\MyFiles\\Classes\\2020 Spring\\cs690\\project\\janossy_lstm_attention\\lstm_test.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\Users\\Master\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\Users\\Master\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run lstm_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num = 10\n",
    "result = [np.empty((5, 5)) for _ in range(num)]\n",
    "result\n",
    "np.shape(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10]) torch.Size([10000, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = train_x.max(dim=2).values\n",
    "# g = g[:, :, None]\n",
    "print(g.shape, mean(train_x, dim=2).sum(dim=1, keepdims=True).shape)\n",
    "# g = g + mean(train_x, dim=2).sum(dim=1, keepdims=True)\n",
    "# g = torch.tanh(g[:,:,None])\n",
    "g = g[:,:,None]\n",
    "loss_function(g, train_y)\n",
    "# train_y.shape\n",
    "# train_x.max(dim=-1, keepdims=True).values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 2, 6, 1, 4, 5, 9, 8, 0])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.arange(10)\n",
    "t[indices] = np.arange(10)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulge = pd.DataFrame(zip([0, 0.5, 1, 1.1, 1.2, 1.2, 1.2, 1.3, 1.3, 1.3], [1.5, 0, 0, 0, 1, 9.2, 11, 9.5, 10, 10]), columns=['z', 'age'])\n",
    "# bulge\n",
    "# height = [i for i, x in enumerate(bulge['z']) if 1<x<1.25]\n",
    "# age1 = [i for i, x in enumerate(bulge['age']) if x<0.1]\n",
    "# age2 = [i for i, x in enumerate(bulge['age']) if 9<x<10]\n",
    "\n",
    "# ageheight1=bulge[height and age1]\n",
    "# ageheight2=bulge[height and age2]\n",
    "ageheight1 = bulge[ (bulge['age']<0.1) & (bulge['z']<1.25) & (bulge['z']>1)]\n",
    "ageheight2 = bulge[ (bulge['age']<10) & (bulge['age']>9) & (bulge['z']<1.25) & (bulge['z']>1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fake data\n",
    "np.random.seed(42)\n",
    "# the variable length of inner lists: [7270,  860, 5390, ..., 1389, 4276, 1249]\n",
    "inner_sizes = np.random.randint(low=1, high=1000, size=10000)\n",
    "ppValues = [np.random.randint(1000, size=i) for i in inner_sizes]\n",
    "# ppValues contains 10000 lists, each having 1 to 1000 elements, each element is a number between 1 to 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13824000000000003"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: -750.0\n",
      "0.2: -647.9719424\n",
      "0.4: -517.9798528\n",
      "0.6: -250.97758719999996\n",
      "0.8: 79.85290239999995\n",
      "0.967: 199.00722445528697\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mar</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apr</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dec</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  month day\n",
       "1   Mar  19\n",
       "0   Apr  20\n",
       "2   Dec   4"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
