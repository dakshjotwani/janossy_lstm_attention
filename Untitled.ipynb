{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import train\n",
    "import transformer\n",
    "importlib.reload(train)\n",
    "importlib.reload(transformer)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def start():\n",
    "    sys.argv = ['train.py', '-data_pkl', 'm30k_deen_shr.pkl', '-embs_share_weight', \n",
    "                '-proj_share_weight', '-label_smoothing', '-save_model', 'trained', \n",
    "                '-b', '16', '-warmup', '128000', '-epoch', '2']\n",
    "    sys.argv = ['train.py', '-data_pkl', 'm30k_deen_shr.pkl', '-embs_share_weight', \n",
    "                '-proj_share_weight', '-label_smoothing', '-save_model', 'trained', '-load_model', 'trained', \n",
    "                '-b', '4', '-warmup', '128000', '-epoch', '150']\n",
    "    train.main()\n",
    "# start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run train.py -data_pkl m30k_deen_shr.pkl -log m30k_deen_shr -embs_share_weight -proj_share_weight -label_smoothing -save_model trained -load_model trained -b 8 -warmup 128000 -epoch 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros((3, 10)).long()\n",
    "b = torch.tensor([1, 1, 2]).long()\n",
    "a.scatter(1, b.view(-1, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4200, 4201, 4202, 4203, 4204],\n",
       "        [4205, 4206, 4207, 4208, 4209],\n",
       "        [4210, 4211, 4212, 4213, 4214],\n",
       "        [4215, 4216, 4217, 4218, 4219],\n",
       "        [4220, 4221, 4222, 4223, 4224]], dtype=torch.int32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[np.arange(0, 25).reshape(5, 5)+((i)*100)+((j)*1000) for i in range(5)] for j in range(16)])\n",
    "a = torch.tensor(a)\n",
    "a[4, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.triu(np.ones((5, 5)))[None, None, :].repeat(16, axis=0)\n",
    "mask = torch.tensor(mask)\n",
    "mask[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5, 5, 5]) torch.Size([16, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# a.masked_fill(mask == 0, -1e9)\n",
    "print(a.shape, mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(num_examples, seq_len, n_dim, std):\n",
    "    train_x = torch.normal(torch.zeros(seq_len*n_dim*num_examples), torch.ones(seq_len*n_dim*num_examples)*std).view(num_examples, seq_len, n_dim)\n",
    "    means = torch.mean(train_x, dim=2)\n",
    "    maxes = torch.max(train_x, dim=2).values\n",
    "    sum_of_means = means.sum(dim=1)\n",
    "    train_y = maxes + sum_of_means[:, None] - means\n",
    "    return train_x, train_y.unsqueeze(-1)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(MyDataset, self).__init__()\n",
    "        assert x.shape[0] == y.shape[0] # assuming shape[0] = dataset size\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "seq_len = 10\n",
    "n_dim = 5\n",
    "num_examples = 10000\n",
    "std = 100\n",
    "train_x, train_y = create_data(num_examples, seq_len, n_dim, std)\n",
    "traindata = MyDataset(train_x, train_y)\n",
    "traindata_tran = MyDataset(train_x, torch.cat((torch.zeros(train_y.shape[:-1]+(4,)), train_y), dim=-1))\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=1024, shuffle=True)\n",
    "trainloader_tran = torch.utils.data.DataLoader(traindata_tran, batch_size=1024, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 36127.8125\n",
      "tensor([0.7424], grad_fn=<SelectBackward>) tensor([407.7269])\n",
      "loss: 34172.546875\n",
      "tensor([2.5558], grad_fn=<SelectBackward>) tensor([38.9618])\n",
      "loss: 35965.18359375\n",
      "tensor([2.6193], grad_fn=<SelectBackward>) tensor([207.2749])\n",
      "loss: 33739.55859375\n",
      "tensor([0.6618], grad_fn=<SelectBackward>) tensor([375.8471])\n",
      "loss: 37242.7265625\n",
      "tensor([-2.6171], grad_fn=<SelectBackward>) tensor([148.2734])\n",
      "loss: 33175.5546875\n",
      "tensor([6.7610], grad_fn=<SelectBackward>) tensor([159.3705])\n",
      "loss: 33109.33984375\n",
      "tensor([7.0350], grad_fn=<SelectBackward>) tensor([47.3907])\n",
      "loss: 31318.56640625\n",
      "tensor([8.6067], grad_fn=<SelectBackward>) tensor([-2.9461])\n",
      "loss: 35650.7578125\n",
      "tensor([9.6214], grad_fn=<SelectBackward>) tensor([-63.3893])\n",
      "loss: 34143.88671875\n",
      "tensor([10.9575], grad_fn=<SelectBackward>) tensor([47.5561])\n",
      "loss: 30501.578125\n",
      "tensor([11.8591], grad_fn=<SelectBackward>) tensor([-59.8083])\n",
      "loss: 30259.765625\n",
      "tensor([10.0630], grad_fn=<SelectBackward>) tensor([6.2234])\n",
      "loss: 33881.4375\n",
      "tensor([14.4159], grad_fn=<SelectBackward>) tensor([34.7394])\n",
      "loss: 31600.62109375\n",
      "tensor([15.5714], grad_fn=<SelectBackward>) tensor([-89.0768])\n",
      "loss: 33911.3671875\n",
      "tensor([16.8049], grad_fn=<SelectBackward>) tensor([47.2737])\n",
      "loss: 31801.12890625\n",
      "tensor([18.2344], grad_fn=<SelectBackward>) tensor([31.8803])\n",
      "loss: 32624.21484375\n",
      "tensor([19.6621], grad_fn=<SelectBackward>) tensor([241.7808])\n",
      "loss: 30675.2421875\n",
      "tensor([21.0995], grad_fn=<SelectBackward>) tensor([320.5489])\n",
      "loss: 32570.650390625\n",
      "tensor([22.4521], grad_fn=<SelectBackward>) tensor([148.1073])\n",
      "loss: 30262.021484375\n",
      "tensor([24.1320], grad_fn=<SelectBackward>) tensor([189.7636])\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(transformer)\n",
    "class janossyLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, janossy_count, dropout=0):\n",
    "        super(janossyLSTM, self).__init__()\n",
    "        self.janossy_count = janossy_count\n",
    "        self.lstm = nn.LSTM(input_size = input_dim, hidden_size = hidden_dim, dropout = dropout)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        # lstm needs [seq_len, batch, input_size]\n",
    "        seq = seq.transpose(0, 1)\n",
    "        \n",
    "        indices = np.arange(seq.size(0))\n",
    "        reverse_indices = np.arange(seq.size(0))\n",
    "        indices_arange = np.arange(seq.size(0))\n",
    "        \n",
    "        result = torch.zeros_like(seq[:,:,0:1])\n",
    "\n",
    "        for _ in range(self.janossy_count):\n",
    "            np.random.shuffle(indices)\n",
    "            reverse_indices[indices] = indices_arange\n",
    "            \n",
    "            permuted_input = seq[indices]\n",
    "            permuted_out, _ = self.lstm(permuted_input)\n",
    "            out = permuted_out[reverse_indices]\n",
    "            result += out[:,:,0:1]\n",
    "\n",
    "        result = result / self.janossy_count\n",
    "        # get result of shape [batch, seq_len, hidden_size]\n",
    "        result = result.transpose(0, 1)\n",
    "        result = torch.log((result+1)/(1-result))\n",
    "        return result\n",
    "\n",
    "# model = janossyLSTM(n_dim, 1, janossy_count=2)\n",
    "model = transformer.Transformer_embed_ready_test(d_model=5, d_inner=100, n_layers=1, n_head=1, d_k=4, d_v=4, dropout=0)\n",
    "loss_function = nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "optimizer = optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-04)\n",
    "\n",
    "for epoch in range(100):\n",
    "    for mini_x, mini_y in trainloader:\n",
    "        model.zero_grad()\n",
    "        out = model(mini_x, mini_y)\n",
    "        \n",
    "        loss = loss_function(out, mini_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch%5 == 0:\n",
    "        print('loss:', loss.item())\n",
    "        print(out[0][0], mini_y[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10]) torch.Size([10000, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2000.1301)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = train_x.max(dim=2).values\n",
    "# g = g[:, :, None]\n",
    "print(g.shape, torch.mean(train_x, dim=2).sum(dim=1, keepdims=True).shape)\n",
    "g = g + torch.mean(train_x, dim=2).sum(dim=1, keepdims=True)\n",
    "# g = torch.tanh(g[:,:,None])\n",
    "g = g[:,:,None]\n",
    "loss_function(g, train_y)\n",
    "# train_y.shape\n",
    "# train_x.max(dim=-1, keepdims=True).values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.0000,   0.0000,   0.0000,   0.0000, 191.0172],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 200.6131],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 126.5630],\n",
       "         ...,\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 169.1883],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 232.0375],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 128.3785]],\n",
       "\n",
       "        [[  0.0000,   0.0000,   0.0000,   0.0000, 481.5238],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 397.1162],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 330.3789],\n",
       "         ...,\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 334.1475],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 486.1726],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 264.0705]],\n",
       "\n",
       "        [[  0.0000,   0.0000,   0.0000,   0.0000,  41.3235],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, -13.2239],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000,  13.0677],\n",
       "         ...,\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000,  22.7467],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, -30.8669],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000,  95.3577]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.0000,   0.0000,   0.0000,   0.0000,  86.3578],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000,  51.5902],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000,  71.2542],\n",
       "         ...,\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 216.8007],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 194.6358],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000,  40.8266]],\n",
       "\n",
       "        [[  0.0000,   0.0000,   0.0000,   0.0000, 198.2770],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 223.2516],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 232.3194],\n",
       "         ...,\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 250.2436],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 197.9384],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 268.1901]],\n",
       "\n",
       "        [[  0.0000,   0.0000,   0.0000,   0.0000,  -7.8791],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, 175.5190],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000,  -7.1791],\n",
       "         ...,\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, -55.1464],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000,  11.6387],\n",
       "         [  0.0000,   0.0000,   0.0000,   0.0000, -64.5019]]])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 2, 6, 1, 4, 5, 9, 8, 0])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.arange(10)\n",
    "t[indices] = np.arange(10)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "Wall time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10):\n",
    "    np.random.shuffle(indices)\n",
    "    t[indices] = tt\n",
    "    print(t[indices])\n",
    "    print(tt[indices][t])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
